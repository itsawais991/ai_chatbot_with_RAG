RAG Chatbot with Streamlit and LangChain
ğŸš€ A Retrieval-Augmented Generation (RAG) chatbot powered by Groq (Llama 3.1 8B), LangChain, and Streamlit. This app allows users to query a PDF document using natural language and get AI-generated responses.

ğŸ“Œ Features
âœ… PDF Document Processing â€“ Upload and extract text from PDFs
âœ… Vector Embeddings â€“ Uses all-MiniLM-L12-v2 for semantic search
âœ… RAG Pipeline â€“ RetrievalQA with Groq's fast LLM
âœ… Chat Interface â€“ Streamlit-based interactive UI
âœ… Session Memory â€“ Remembers conversation history

âš™ï¸ Setup
Prerequisites
Python 3.10+

Groq API Key (Free tier available)

Installation
Clone the repository

sh
git clone https://github.com/yourusername/rag-chatbot.git
cd rag-chatbot
Install dependencies

sh
pip install -r requirements.txt
Set up environment variables
Create a .env file and add your Groq API key:

text
GROQ_API_KEY="your_api_key_here"
Add a PDF
Place your PDF in the project folder and update pdf_name in app.py.

ğŸš€ Running the App
sh
streamlit run app.py
The app will open in your browser at http://localhost:8501.

ğŸ› ï¸ Customization
Changing the LLM
Replace model="llama-3.1-8b-instant" with other Groq-supported models:

mixtral-8x7b-32768

gemma-7b-it

Modifying the Prompt
Edit the groq_sys_prompt in app.py:

python
groq_sys_prompt = ChatPromptTemplate.from_template("""
    You are a helpful assistant. Answer concisely: {user_prompt}.
""")
Adjusting Chunk Size
Modify RecursiveCharacterTextSplitter parameters:

python
text_splitter=RecursiveCharacterTextSplitter(
    chunk_size=1000,  # Increase for larger docs
    chunk_overlap=100  # Helps maintain context
)
ğŸ“‚ Project Structure
text
.
â”œâ”€â”€ app.py                # Main Streamlit application
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .env                  # API keys (gitignored)
â””â”€â”€ your_document.pdf     # Sample PDF for testing
ğŸ“œ License
MIT License â€“ Free for personal and commercial use.

ğŸ™Œ Credits
LangChain â€“ RAG framework

Groq â€“ Ultra-fast LLM inference

Streamlit â€“ Web app deployment

ğŸ›  Need help? Open an issue or contribute!
ğŸ”— Live Demo: [Coming Soon]
